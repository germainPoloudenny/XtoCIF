\section{Background and Related Work}

\paragraph{PXRD-driven structure solution.}
Powder diffraction remains the most practical probe for crystalline electrodes, catalysts, and battery intermediates, yet solving unknown structures from one-dimensional scattering traces is still dominated by iterative protocols such as Rietveld refinement implemented in widely used suites like GSAS-II and FullProf, simulated annealing, and charge-flipping searches \cite{toby2013gsas2,rodriguezcarvajal1993fullprof}. These workflows assume accurate peak indexing, carefully tuned peak-shape models, and access to expert priors on symmetry or stoichiometry, all of which are hard to guarantee in high-throughput screening or when metastable phases coexist. Ambiguities accumulate when preferred orientation, sample displacement, or low signal-to-noise dramatically alter the profile, motivating approaches that can translate raw PXRD intensities into candidate structures without manual feature engineering.

\paragraph{Learning-based PXRD interpretation.}
Curated PXRD corpora (e.g., NOMA, CHILI-100K) have enabled fast discriminative tools: BraggNN accelerates Bragg-peak analysis, and neural classifiers infer crystal symmetry directly from powder patterns \cite{liu2021braggnn,vecsei2019symmetry}. These approaches excel at labeling (phases, symmetry) or producing embeddings but stop short of atomistic reconstruction. Assumptions such as single-phase patterns and fixed broadening also limit robustness to experimental artifacts and mixtures, motivating generative models.

\paragraph{Generative crystal models.}
Composition-conditioned generators span diffusion models, normalizing flows, and autoregressive tokenizers \cite{jiao2023crystal,millerflowmm,antunes2024crystalstructuregenerationautoregressive,gruver2024finetuned,mohanty2024crystext}. They can enumerate symmetry-consistent lattices and emit plausible CIFs, but typically require clean descriptors (stoichiometry, lattice parameters, space group) and curated prompts before decoding \cite{jiao2023crystal,antunes2024crystalstructuregenerationautoregressive}. Without an experimental conditioner, practitioners must simulate diffraction for large candidate pools to find PXRD-consistent structures, which is costly and ill-suited to rapid, experiment-in-the-loop workflows \cite{gruver2024finetuned,mohanty2024crystext}.

\paragraph{Diffraction-conditioned generative models.}
Recent efforts have started to close this gap by injecting scattering data into the generative loop: DeepStruc couples pair-distribution functions with graph decoders, conditional diffusion has been explored on electron diffraction, and \deCIFer introduced autoregressive CIF decoding from PXRD embeddings. However, \deCIFer depends on a single decoding strategy, lacks an explicit mechanism to compare multiple hypotheses against the observed trace, and its training recipe remains costly to reproduce at scale. \xtoCIF targets these pain points: we reorganize the training system for multi-GPU efficiency, decouple CIF synthesis from downstream diffraction-aware ranking, and introduce a test-time scaling strategy that surfaces a calibrated portfolio of candidates. This rethinking of both streams of prior art, namely classical PXRD analysis and modern generative modeling, grounds the methodological choices detailed in the next section.
