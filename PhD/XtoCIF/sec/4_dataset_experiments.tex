\section{Dataset and Experiments}
\label{sec:dataset}

\subsection{Benchmarks and Splits}
All quantitative results in this paper are obtained on \textbf{NOMA}, which aggregates relaxed structures from NOMAD, OQMD, and Materials Project snapshots (April 2023 cut-off) and supplies synthetic PXRD traces computed with a fixed instrumental model~\cite{nomad2019,kirklin2015open,Jain2013MaterialsProject}. After deduplicating by reduced formula and removing entries with unresolved oxidation states, the working set contains 2.1\,M CIFs. We stratify this pool by Bravais class and element count, reserving 2.0\,M structures for training, 50\,k for validation, and 20\,k for testing. We additionally maintain data-processing scripts for \textbf{CHILI-100K}~\cite{FriisJensenJohansen2024,COD2009}, the experimental collection of 100\,k powder scans gathered with a laboratory diffractometer. These utilities regenerate CHILI traces with the same inference pipeline used on NOMA, producing a descriptor-free pilot evaluation on 841 held-out scans (Table~\ref{tab:chili-vs-noma}). Both corpora share the 373-token vocabulary inherited from \deCIFer, ensuring backwards compatibility whenever we alternate between synthetic and experimental diffraction.

\subsection{PXRD Synthesis and Conditioning Regimes}
To emulate realistic diffraction variability, every CIF is passed through the reciprocal-space simulator described in Section~\ref{sec:dataset}: by default we evaluate the pseudo-Voigt profile on a \(q\in[0,10]\,\text{\AA}^{-1}\) grid with \(\Delta q = 0.01\), sample FWHM from \([0.001, 0.10]\), and draw Gaussian noise from \([0.001, 0.05]\). The released configuration keeps the intensity scale at one and disables Bernoulli masking, but both options are exposed for experiments that require them. For inference we regenerate the PXRD trace from the held-out CIF using the same simulator so that comparisons are not confounded by mismatched instrumental kernels. Experiments are run under three conditioning regimes: \emph{No descriptors} (PXRD only), \emph{Comp} (PXRD plus a stoichiometric hint), and \emph{Comp+SG} (PXRD plus stoichiometry and Hermann--Mauguin symbol). Descriptor information is preserved by keeping the relevant text in the prompt through the evaluation harness, so no additional learned tokens are introduced. These regimes reveal how \xtoCIF behaves as metadata availability ranges from absent to highly informative.

\subsection{Training and Inference Configuration}
Unless otherwise noted, models are trained for 300\,k optimizer steps with batch size 32\(\times\)40 gradient accumulation on two NVIDIA A100 GPUs (the released configuration exposes shorter or longer schedules through a single iteration-count knob). We reuse the optimizer hyperparameters listed in Section~\ref{sec:reconstruction-model} and apply teacher-forcing on randomly sampled augmentation levels. Validation snapshots are taken every 2\,k steps using the in-distribution augmentation profile.

At test time we run the same evaluation harness. The default configuration samples a single hypothesis (\(B=1\)) with temperature \(1.0\). Deterministic beam search is available with a configurable width \(B\), and automation handles the beam-width sweeps reported later in the paper. After generation we compute \(\Rwp\) and RMSD for every candidate and optionally retain the top-\(k\) hypotheses per CIF via a post hoc filtering stage. All best-of-beam statistics reported in the paper refer to this filtering step, and medians/means are computed over the resulting candidate sets for each evaluation run.

\subsection{Evaluation Metrics}
We report three complementary metrics on NOMA-test: (1) \textbf{Validity}, the fraction of CIFs that pass syntax checks, yield a stable lattice, and contain plausible bonds; (2) \textbf{Match Rate (MR)}, the percentage of samples whose symmetry-aligned RMSD falls below 0.5\,\AA\ while respecting composition; and (3) the \textbf{weighted-profile residual} \(\Rwp\), obtained by comparing the simulated PXRD of each candidate against the reference trace. When the conditioning regime provides no descriptors, we still enforce exact atomic identities to avoid artificially inflating MR. All metrics are reported as mean \(\pm\) standard deviation over the retained candidates from a given evaluation run; whenever we mention “best-of-beam,” we refer to the post-hoc filtering step described above.

\subsection{Experiment Suite}
The main study contrasts \xtoCIF with the original \deCIFer under all conditioning regimes on NOMA-test, highlighting the impact of the streamlined training loop and the decoding/reranking stack. A second set of experiments sweeps beam size and the number of reranked candidates to map out the test-time scaling frontier (Figure~\ref{fig:beam_rmsd_match}). Finally, we ablate each ingredient: conditioning augmentations, beam width, and \(\Rwp\)-based filtering, to quantify its contribution to MR and \(\Rwp\) in the descriptor-free regime, which is the most challenging real-world setting. The same infrastructure now powers the pilot CHILI-100K evaluation summarized in Section~\ref{sec:chili-eval}.
