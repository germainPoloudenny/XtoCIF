\section{Training and Implementation Details}
\label{sec:supp:impl}

We detail here the model, training, and evaluation settings used in all \xtoCIF experiments, with enough information to reproduce the reported results or adapt the configuration to new PXRD datasets.

\paragraph{Model and tokenizer.}
Instead of repeating Section~\ref{sec:reconstruction-model}, we collect the reproducibility knobs that are not spelled out in the main text. All runs share the same hyperparameters: \(\texttt{block\_size}=3076\), \(n_{\text{layer}} = n_{\text{head}} = 8\), \(n_{\text{embd}}=512\), dropout \(=0\), and seed \(=1337\). The tokenizer is kept frozen across all experiments: its 372 symbols map \texttt{data\_}\(\rightarrow 124\), newline \(\rightarrow 142\), and padding \(\rightarrow 371\). No learned descriptor tokens are added; when descriptors are enabled, the dataloader keeps the raw CIF headers. Packed batches contain either one long CIF or multiple short CIFs truncated to the 3,076-token context. Boundary masking zeroes all cross-sample attention weights so that conditioning snippets never leak between CIFs.

\paragraph{PXRD conditioner.}
The pseudo-Voigt simulator is evaluated over \(N_q = (10-0)/0.01 = 1000\) samples, and the chunk size is adapted so that intermediate tensors stay under \(\sim 256\) MB. For each sample we draw FWHM \(\sim \mathcal{U}[0.001, 0.10]\), fix \(\eta=0.5\), sample noise \(\sim \mathcal{U}[0.001, 0.05]\), and apply per-trace intensity scales \(\sim \mathcal{U}[0.95, 1.0]\); mask probability is set to zero in the training configuration. The flattened \(1000\)-bin trace is projected with a 2-layer MLP (Linear-ReLU-Linear) to 512 dimensions, and those embeddings are inserted next to every \texttt{data\_} token, matching the conditioning scheme in nanoGPT-style decoders.

\paragraph{Optimization and schedule.}
We train with AdamW using the same hyperparameters as the public \deCIFer release. In all reported runs the per-GPU micro-batch size is 32 sequences, and the global effective batch size is kept fixed at 1{,}280 sequences. On a single GPU this corresponds to 40 gradient-accumulation steps (\(32\times40 = 1280\)); on the 2-GPU runs used for the throughput table we set the accumulation factor to 20 per device so that \(32\times20\times2 = 1280\) remains unchanged. The trainer divides the accumulation steps by the world size to enforce this convention. We apply teacher forcing under randomly sampled PXRD augmentation parameters, and take validation snapshots every 2\,k steps using the in-distribution augmentation profile.

\paragraph{Evaluation harness.}
The evaluation pipeline mirrors the training stack. For each CIF in the test split we regenerate its PXRD trace with the same simulator, run the decoder either with stochastic sampling (\(B = 1\)) or deterministic beam search with configurable width \(B\), and then compute \(\Rwp\), RMSD, and validity indicators for every candidate. Post-hoc filtering retains the top-ranked hypotheses per CIF according to \(\Rwp\), and all match-rate and \(\Rwp\) statistics reported in the main paper are computed on this filtered set.

\paragraph{Qualitative case grid.}
To make the behavioral differences between the default decoder and the beam-search + \(\Rwp\) reranking stack tangible, we render Fig.~\ref{fig:qual-case-grid} by sampling matched successes and failures from the descriptor-free evaluation logs. Ground-truth PXRD traces (solid blue) are overlaid with generated traces (dashed orange), while adjacent 3D panels visualize the corresponding crystal geometries with successes positioned above failures. The annotations expose \(\Rwp\), RMSD, or failure causes, linking qualitative behavior to the metrics reported in the main text.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{Figures/xtocif_case_grid.png}
  \vspace{-0.5ex}
  \caption{PXRD and structure cases for the default decoder (left block) versus beam search + \(\Rwp\) reranking (right block). Each row shows a successful reconstruction (top) or a still-mismatched CIF (bottom) from NOMA, with overlaid PXRD traces and 3D structure views. The annotations record \(\Rwp\), RMSD, or failure causes, allowing the reported numbers to be correlated with the visual quality.}
  \label{fig:qual-case-grid}
\end{figure}
\FloatBarrier

\paragraph{\(\Rwp\) calibration.}
Figure~\ref{fig:rwp-vs-rmsd} quantifies how \(\Rwp\) orders the \(B{=}5\) beam on the descriptor-free NOMA and CHILI sweeps. Each point corresponds to one beam hypothesis (4{,}995 on NOMA, 4{,}205 on CHILI) ranked by \(\Rwp\) and colored by whether the validator produced a finite RMSD (non-matches are clamped to \(0.6\,\text{\AA}\) solely for visual separation). On NOMA, the 386 hypotheses that satisfy the \(0.5\,\text{\AA}\) RMSD bound span 84 CIFs and yield a Spearman correlation \(r=0.25\) between \(\Rwp\) and RMSD; \(295/386\) of those matches (\(76~\%\)) fall below \(\Rwp\le 0.2\) and none exceed \(\Rwp=0.8\), so reranking by \(\Rwp\) tends to surface diffraction-consistent structures before post-hoc RMSD screening, with most matches concentrated in the low-\(\Rwp\) regime. CHILI produces only 15 such matches (across 3 CIFs), which appear in the lower-left corner while the remaining 4{,}190 hypotheses accumulate at \(\Rwp>0.3\) and fail RMSD. This separation explains why \(\Rwp\) reranking still reduces the mean \(\Rwp\) on experimental scans despite the low absolute match rate.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{Figures/new/rwp_vs_rmsd_scatter.pdf}
  \vspace{-0.5ex}
  \caption{\(\Rwp\) vs.\ RMSD for the top-\(5\) beam hypotheses on descriptor-free NOMA (left) and CHILI (right). Points are color-coded by the presence of a finite RMSD; failures are plotted at \(0.6\,\text{\AA}\) for readability. The reported Spearman coefficient is computed on RMSD matches only (NOMA: \(n{=}386\), \(r=0.25\); CHILI: \(n{=}15\), insufficient spread for a stable estimate).}
  \label{fig:rwp-vs-rmsd}
\end{figure}
\FloatBarrier

\paragraph{Training throughput breakdown.}
Figure~\ref{fig:training-breakdown} complements the engineering discussion from the main manuscript by plotting the per-iteration wall-clock time (log axis) together with the resulting throughput for every optimization stage listed in Table~1. The drop from the reference implementation to the streamlined dataloader removes host/device stalls, GPU-resident PXRD augmentation eliminates the remaining bottleneck, and distributed training on two A100s scales the already-optimized loop almost linearly. GPU counts are annotated above each bar for clarity; the underlying statistics are taken from the same monitoring logs that produced Table~1.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{Figures/new/training_breakdown.pdf}
  \vspace{-0.5ex}
  \caption{Training-speed breakdown. Bars show iteration time (log-scale, with standard deviation) while the black line reports throughput. Each stage corresponds to one cumulative engineering change, mirroring the throughput table in the main manuscript; GPU counts per stage are annotated above the bars.}
  \label{fig:training-breakdown}
\end{figure}
\FloatBarrier

\section{Dataset Coverage and Augmentation Variability}

Section~\ref{sec:dataset} summarizes the composition diversity, PXRD augmentations, and instrument response we emulate on NOMA and CHILI, but the discussion remains textual in the main paper. Figure~\ref{fig:dataset-augment-panel} complements this summary with visual context: panel~(a) compares the stoichiometric complexity of 1{,}000 held-out NOMA CIFs against the 841-scan CHILI pilot (unique species per CIF), panel~(b) shows the pseudo-Voigt full-width-at-half-maximum and Gaussian noise draws used during training (100{,}000 samples drawn from the published ranges), and panel~(c) overlays the mean normalized PXRD traces together with the 10th--90th percentile envelopes for both corpora. The CHILI spectra exhibit the elevated background and broadened peaks that degrade the RMSD matches in Section~\ref{sec:chili-eval}, while the augmentation histogram highlights the instrument coverage we sweep at training time.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{Figures/new/dataset_augmentation_panel.pdf}
  \vspace{-0.5ex}
  \caption{Dataset coverage and PXRD augmentation variability. (a) Histograms of unique elements per CIF on the descriptor-free NOMA test slice (blue) versus the CHILI pilot set (orange). (b) Distribution of pseudo-Voigt full-width-at-half-maximum and additive noise draws sampled during training; both follow the uniform ranges used in the experiments. (c) Mean normalized PXRD traces with 10th--90th percentile bands for NOMA (blue) and CHILI (orange), highlighting the elevated background and broadened peaks in experimental scans.}
  \label{fig:dataset-augment-panel}
\end{figure}
\FloatBarrier

\section{CHILI-100K Domain Gap Diagnostics}

The metrics in Section~\ref{sec:chili-eval} show that CHILI-100K dramatically stresses the PXRD simulator and validator. Figure~\ref{fig:chili-domain-gap} decomposes those numbers. The left panel overlays the \(\Rwp\) distributions for NOMA and CHILI, revealing a large shift toward \(\Rwp\!\approx 0.8\) on experimental scans. The middle panel converts RMSD matches into stacked fractions: only 3 out of 841 CHILI samples meet the 0.5~\AA\ bound even though the tokenizer still produces syntactically valid CIFs. The right panel displays a representative CHILI scan (top 1\% \(\Rwp\)), highlighting the drifting baseline and asymmetric peaks that the current reciprocal-space simulator cannot reproduce. These diagnostics justify the proposed simulator re-parameterization and mixed fine-tuning plan.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{Figures/new/chili_domain_gap.pdf}
  \vspace{-0.5ex}
  \caption{NOMA versus CHILI-100K diagnostics. (Left) Histogram of \(\Rwp\) for descriptor-free runs; (middle) stacked bars showing the symmetry-aware match rate (RMSD \(\le 0.5\,\text{\AA}\)); (right) one CHILI diffractogram with a background shift that the simulator misses.}
  \label{fig:chili-domain-gap}
\end{figure}
\FloatBarrier
